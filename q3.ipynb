{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89344af",
   "metadata": {},
   "source": [
    "question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45591d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data \n",
    "train = pd.read_csv(\"nyc311_NYPD_merged.csv\")\n",
    "test = pd.read_csv(\"nyc311_NYPD_test_merged.csv\")\n",
    "\n",
    "# Create new variable over3h.\n",
    "train['over3h'] = train['Duration (hours)'].\\\n",
    "    apply(lambda x: 1 if x >= 3 else 0)\n",
    "test['over3h'] = test['Duration (hours)'].\\\n",
    "    apply(lambda x: 1 if x >= 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cef48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a hour variable with integer values from 0 to 23\n",
    "train['hour'] = pd.to_datetime(train['Created Date']).dt.hour\n",
    "test['hour'] = pd.to_datetime(test['Created Date']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3eb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a variable represent the ratio of median_home_value to median_household_income\n",
    "train['house_income_ratio'] = train['median_home_value'] / train['median_household_income']\n",
    "test['house_income_ratio'] = test['median_home_value'] / train['median_household_income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cases with missing values for certain columns\n",
    "train = train.dropna(subset=['hour', 'Day type', 'Complaint Type', 'Community Board',\\\n",
    "                 'Resolution Description', 'Open Data Channel Type','population_density',\\\n",
    "                 'median_home_value', 'house_income_ratio'])\n",
    "test = test.dropna(subset=['hour', 'Day type', 'Complaint Type', 'Community Board',\\\n",
    "                 'Resolution Description', 'Open Data Channel Type','population_density',\\\n",
    "                 'median_home_value', 'house_income_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da095bee",
   "metadata": {},
   "source": [
    "When using the fitted model to predict the test data, we noticed that there are certain features that appear only in the testing data (3 cases) and certain features that appear only in the training data (6 cases). Therefore, we need to revisit this step and drop these cases before proceeding with the fit and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6505a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cases with certain values for certain columns\n",
    "test = test.drop(test[test['Community Board'] == '28 BRONX'].index)\n",
    "test = test.drop(test[test['Community Board'] == '80 QUEENS'].index)\n",
    "test = test.drop(test[test['Complaint Type'] == 'Squeegee'].index)\n",
    "train = train.drop(train[train['Community Board'] == '27 BRONX'].index)\n",
    "train = train.drop(train[train['Community Board'] == '81 QUEENS'].index)\n",
    "train = train.drop(train[train['Resolution Description'] == \\\n",
    "'Your complaint has been received by the Police Department and additional information will be available later.'].index)\n",
    "train = train.drop(train[train['Open Data Channel Type'] == 'UNKNOWN'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b34945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21354, 114)\n"
     ]
    }
   ],
   "source": [
    "# Get the training data\n",
    "# Separate the categorical and continuous variables into separate dataframes\n",
    "train_categorical_variables = train[['hour', 'Day type', 'Complaint Type', 'Community Board',\\\n",
    "                 'Resolution Description', 'Open Data Channel Type']]\n",
    "train_continuous_variables = train[['population_density', 'median_home_value', 'house_income_ratio']]\n",
    "\n",
    "# Perform one-hot encoding on the categorical variables\n",
    "train_categorical_encoded = pd.get_dummies(train_categorical_variables)\n",
    "# Combine the one-hot encoded categorical variables with the continuous variables\n",
    "X_train = pd.concat([train_categorical_encoded, train_continuous_variables], axis=1)\n",
    "print(X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed4c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19253, 114)\n"
     ]
    }
   ],
   "source": [
    "# Get the testing data\n",
    "# Separate the categorical and continuous variables into separate dataframes\n",
    "test_categorical_variables = test[['hour', 'Day type', 'Complaint Type', 'Community Board',\\\n",
    "                 'Resolution Description', 'Open Data Channel Type']]\n",
    "test_continuous_variables = test[['population_density', 'median_home_value', 'house_income_ratio']]\n",
    "\n",
    "# Perform one-hot encoding on the categorical variables\n",
    "test_categorical_encoded = pd.get_dummies(test_categorical_variables)\n",
    "\n",
    "# Combine the one-hot encoded categorical variables with the continuous variables\n",
    "X_test = pd.concat([test_categorical_encoded, test_continuous_variables], axis=1)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0dde604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get y for both the training and test data\n",
    "y_train = train['over3h'].values\n",
    "y_test = test['over3h'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2b557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Fit SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b50405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Fit decision tree\n",
    "tree1 = tree.DecisionTreeClassifier()\n",
    "tree1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe646db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7325"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ad4966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the predicted values\n",
    "svm_pred = svm.predict(X_test)\n",
    "tree1_pred = tree1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef952e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model with default parameters\n",
    "from sklearn.metrics import confusion_matrix, \\\n",
    "accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Confusion matrix\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "tree1_cm = confusion_matrix(y_test, tree1_pred)\n",
    "\n",
    "# Accuracy\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "tree1_acc = accuracy_score(y_test, tree1_pred)\n",
    "\n",
    "# Precision\n",
    "svm_precision = precision_score(y_test, svm_pred, zero_division=1)\n",
    "tree1_precision = precision_score(y_test, tree1_pred)\n",
    "\n",
    "# Recall\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "tree1_recall = recall_score(y_test, tree1_pred)\n",
    "\n",
    "# F1-score\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "tree1_f1 = f1_score(y_test, tree1_pred)\n",
    "\n",
    "# AUC\n",
    "svm_auc = roc_auc_score(y_test, svm_pred)\n",
    "tree1_auc = roc_auc_score(y_test, tree1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3c0937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results:\n",
      "Confusion matrix:\n",
      "[[15471     0]\n",
      " [ 3782     0]]\n",
      "Accuracy: 0.8035630810782736\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "AUC: 0.5\n",
      "decision tree results:\n",
      "Confusion matrix:\n",
      "[[13659  1812]\n",
      " [ 2327  1455]]\n",
      "Accuracy: 0.7850205162831766\n",
      "Precision: 0.44536271808999084\n",
      "Recall: 0.38471708090957163\n",
      "F1-score: 0.4128245141154773\n",
      "AUC: 0.6337973614747586\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM results:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(svm_cm)\n",
    "print(\"Accuracy:\", svm_acc)\n",
    "print(\"Precision:\", svm_precision)\n",
    "print(\"Recall:\", svm_recall)\n",
    "print(\"F1-score:\", svm_f1)\n",
    "print(\"AUC:\", svm_auc)\n",
    "\n",
    "print(\"decision tree results:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(tree1_cm)\n",
    "print(\"Accuracy:\", tree1_acc)\n",
    "print(\"Precision:\", tree1_precision)\n",
    "print(\"Recall:\", tree1_recall)\n",
    "print(\"F1-score:\", tree1_f1)\n",
    "print(\"AUC:\", tree1_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fed8e",
   "metadata": {},
   "source": [
    "We observed that the SVM model performed poorly with the default parameters. To improve its performance, we decided to scale the continuous variables and use cross-validation to find the optimal hyperparameters. However, the SVM model took too long to train and did not converge even after running for half an hour.\n",
    "\n",
    "In contrast, the decision tree model provided accurate predictions with the default parameters and was much more efficient than the SVM model. Therefore, we decided to use the decision tree model for further optimazition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34358e6",
   "metadata": {},
   "source": [
    "Here are the syntax that tried to optimize svm parameters\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale the continuous variables \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cont_scaled = scaler.fit_transform(train_continuous_variables)\n",
    "X_test_cont_scaled = scaler.transform(test_continuous_variables)\n",
    "X_train_cont_scaled = pd.DataFrame(X_train_cont_scaled, columns=['scaled1', 'scaled2', 'scaled3'])\n",
    "X_test_cont_scaled = pd.DataFrame(X_test_cont_scaled, columns=['scaled1', 'scaled2', 'scaled3'])\n",
    "train_categorical_encoded = train_categorical_encoded.reset_index()\n",
    "test_categorical_encoded = test_categorical_encoded.reset_index()\n",
    "X_train_s = pd.concat([train_categorical_encoded, X_train_cont_scaled], axis=1)\n",
    "X_test_s = pd.concat([test_categorical_encoded, X_test_cont_scaled], axis=1)\n",
    "\n",
    "# Fit SVM with scaled variables\n",
    "svm2 = SVC()\n",
    "svm2.fit(X_train_s, y_train)\n",
    "\n",
    "# define the hyperparameter space to search over for svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1],\n",
    "              'gamma': [0.01, 0.1, 1, 'scale', 'auto'],\n",
    "              'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "\n",
    "# perform cross-validation with GridSearchCV\n",
    "grid_search = GridSearchCV(svm2, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_s, y_train)\n",
    "\n",
    "# print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0c03149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.001, 'criterion': 'entropy', 'min_impurity_decrease': 0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the hyperparameter grid \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'min_impurity_decrease': [0, 1e-5, 1e-4, 1e-3],\n",
    "              'ccp_alpha': [0.0, 1e-5, 1e-4, 1e-3, 0.01, 0.1]}\n",
    "\n",
    "# perform cross-validation with GridSearchCV\n",
    "grid_search = GridSearchCV(tree1, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters found\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78256fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use parameters from cross-validation to train another model\n",
    "tree2 = tree.DecisionTreeClassifier(criterion='entropy', ccp_alpha=0.001, min_impurity_decrease=0)\n",
    "tree2 = tree2.fit(X_train, y_train)\n",
    "tree2.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6d50d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the predicted values\n",
    "tree2_pred = tree2.predict(X_test)\n",
    "\n",
    "# evaluate the model \n",
    "\n",
    "# Confusion matrix\n",
    "tree2_cm = confusion_matrix(y_test, tree2_pred)\n",
    "\n",
    "# Accuracy\n",
    "tree2_acc = accuracy_score(y_test, tree2_pred)\n",
    "\n",
    "# Precision\n",
    "tree2_precision = precision_score(y_test, tree2_pred)\n",
    "\n",
    "# Recall\n",
    "tree2_recall = recall_score(y_test, tree2_pred)\n",
    "\n",
    "# F1-score\n",
    "tree2_f1 = f1_score(y_test, tree2_pred)\n",
    "\n",
    "# AUC\n",
    "tree2_auc = roc_auc_score(y_test, tree2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62b84758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree2 results:\n",
      "Confusion matrix:\n",
      "[[15131   340]\n",
      " [ 3012   770]]\n",
      "Accuracy: 0.8258972627642446\n",
      "Precision: 0.6936936936936937\n",
      "Recall: 0.20359598096245374\n",
      "F1-score: 0.3147996729354048\n",
      "AUC: 0.5908096897896102\n"
     ]
    }
   ],
   "source": [
    "print(\"decision tree2 results:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(tree2_cm)\n",
    "print(\"Accuracy:\", tree2_acc)\n",
    "print(\"Precision:\", tree2_precision)\n",
    "print(\"Recall:\", tree2_recall)\n",
    "print(\"F1-score:\", tree2_f1)\n",
    "print(\"AUC:\", tree2_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3972e602",
   "metadata": {},
   "source": [
    "Cross-validation was used to optimize the tuning parameters for building the second decision tree model with the objective of minimizing overfitting and maximizing AUC. While the second model (tree2) performed better on accuracy and precision, it did not perform as well as the first model (tree1) on other metrics such as recall, F1 score, and AUC. However, tree2 had significantly fewer nodes than tree1. Overall, both models performed adequately and the choice of model would depend on the specific metric that is more important for the task at hand. For instance, if higher precision is desired, then tree1 would be the preferred choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
