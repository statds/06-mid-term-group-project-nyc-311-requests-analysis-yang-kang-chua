---
title: "Midterm Project"
author: "Yang Kang Chua, Shen, Tong"
date: "March 3, 2023"
format:
  html:
    code-fold: true
  pdf: 
    geometry: 
      - top=30mm
      - left=20mm
jupyter: python3
---

```{python}
import numpy as np
import pandas as pd

nyc311 = pd.read_csv("nyc311_011523-012123_by022023.csv")

nyc311.head()

```

Get a statistical summary

```{python}
nyc311.describe()
```

Looks good! Lets take a look at the number of missing values.

```{python}
nyc311.isna().sum()
```

Get the type of the data frame
```{python}
nyc311.info();
```

Convert the time to date time format.

```{python}
nyc311['Created Date'] = pd.to_datetime(nyc311['Created Date'], errors='coerce')
nyc311['Closed Date'] = pd.to_datetime(nyc311['Closed Date'], errors='coerce')
```
Let take a look on if `Closed Date` earlier than `Created Date`.

```{python}
# Create a filter to find if the Closed Date is earlier and Created Date

Filter_1 = nyc311[nyc311['Created Date'] > nyc311['Closed Date']]

Filter_1.head()
```
Check missing value percentage

```{python}
# Find missing value
missing_value = nyc311.isnull()

#Divide the full data length to get the percentage
missing_value = missing_value.sum()/len(nyc311)

#Convert into dataframe
missing_value = missing_value.to_frame()

#Name the column
missing_value.columns = ['Missing Percentage']

#Display
missing_value

```

Few thing we can do to clean the data:

* Reorganize the `Created Date` and `Closed Date`.
* Missing Value from `Incident Zip` can be found using `Latitude` and `Longitude` using `uszipcode`.
* `Latitude` and `Longitude` can be found using the available `Incident Address`, `Street Name`, `Cross Street 1`, `Cross Street 2`, `Intersection Street 1`, `Intersection Street 2` or as known as `Address Type`.
* We can get `X Coordinate (State Plane)`and `Y Coordinate (State Plane)` using `stateplane`.
* Update `Borough` from `Incident Zip`.

Begin by Reorganize the `Created Date` and `Closed Date`.

```{python}
# Create a copy of a Closed Date(Created Date)
Created_Date = Filter_1['Closed Date'].copy()

for index in Filter_1.index:
    Filter_1.loc[index,['Closed Date']] = Filter_1['Created Date'][index]
    Filter_1.loc[index,['Created Date']] = Created_Date[index]

Filter_1.head()
```

Put into the original data.

```{python}
for index in Filter_1.index:
  nyc311.loc[index,['Created Date']] = Filter_1['Created Date'][index]
  nyc311.loc[index,['Closed Date']]  = Filter_1['Closed Date'][index]

```

Now work on getting `Latitude` and `Longitude` can be found using the available `Incident Address`, `Street Name`, `Cross Street 1`, `Cross Street 2`, `Intersection Street 1`, `Intersection Street 2` or as known as `Address Type`.

Begin with solving `Address Type` that is `INTERSECTION`.

```{python}
# Get the remaining data that is missing with Latitude
Filter_1 = nyc311[nyc311['Latitude'].isnull()]

# Get the data that contain INTERSECTION
Filter_1 = Filter_1[Filter_1['Address Type'] =='INTERSECTION']

from geopy.geocoders import Nominatim
from geopy.geocoders import GoogleV3
from geopy.extra.rate_limiter import RateLimiter

Intersection = Filter_1['Intersection Street 1'] + ' @ ' + Filter_1['Intersection Street 2'] + ' NY'

for index in Intersection.index:
    geocode = RateLimiter(GoogleV3(api_key='AIzaSyDhsJ5roz0w0ll0YegLJZn-niSBjm1ns5A').geocode, min_delay_seconds=1)
    location = geocode(Intersection[index], timeout = 10)
    if location is not None:
        Filter_1.loc[index,['Latitude',"Longitude"]] = [location.latitude,location.longitude]
        
# Update the data
for index in Filter_1.index:
    nyc311.loc[index,'Latitude']   = Filter_1['Latitude'][index]
    nyc311.loc[index,'Longitude'] = Filter_1['Longitude'][index]

```
Then work with address type `BLOCKFACE`.
```{python}
Filter_1 = nyc311[nyc311['Latitude'].isnull()]

Filter_1 = Filter_1[Filter_1['Address Type'] == 'BLOCKFACE']

Cross_Street = Filter_1['Cross Street 1'] + ' @ ' + Filter_1['Cross Street 2'] + ' NY '

for index in Cross_Street.index:
    if not Filter_1['Cross Street 1'][index] == Filter_1['Cross Street 2'][index]:
        if Filter_1['Cross Street 2'][index] is not np.nan:
            if Filter_1['Cross Street 2'][index] != 'SEE COMMENTS FOR CROSS ST':
                geocode = RateLimiter(GoogleV3(api_key='AIzaSyDhsJ5roz0w0ll0YegLJZn-niSBjm1ns5A').geocode, min_delay_seconds=1)
                location = geocode(Cross_Street[index], timeout = 10)
                if location is not None:
                    Filter_1.loc[index,['Latitude',"Longitude"]] = [location.latitude,location.longitude]

# Use the Street Name and Cross Street 1 to get the latitude and longitude
Filter_2 = Filter_1[Filter_1['Latitude'].isnull()]

Street_Cross = Filter_2['Street Name'] + ' @ ' + Filter_2['Cross Street 1'] + ' NY '

for index in Street_Cross.index:
    geocode = RateLimiter(GoogleV3(api_key='AIzaSyDhsJ5roz0w0ll0YegLJZn-niSBjm1ns5A').geocode, min_delay_seconds=1)
    location = geocode(Street_Cross[index], timeout = 10)
    if location is not None:
        Filter_1.loc[index,['Latitude',"Longitude"]] = [location.latitude,location.longitude]

for index in Filter_1.index:
    nyc311.loc[index,'Latitude']   = Filter_1['Latitude'][index]
    nyc311.loc[index,'Longitude'] = Filter_1['Longitude'][index]
```

Work on Address Type = `ADDRESS`
```{python}
Filter_1 = nyc311[nyc311['Latitude'].isnull()]
Filter_1 = Filter_1[Filter_1['Address Type'] == 'ADDRESS']

Address = Filter_1['Incident Address'] + ' NY '

for index in Address.index:
    geocode = RateLimiter(GoogleV3(api_key='AIzaSyDhsJ5roz0w0ll0YegLJZn-niSBjm1ns5A').geocode, min_delay_seconds=1)
    location = geocode(Address[index], timeout = 10)
    if location is not None:
        Filter_1.loc[index,['Latitude',"Longitude"]] = [location.latitude,location.longitude]

# Update
for index in Filter_1.index:
    nyc311.loc[index,'Latitude']   = Filter_1['Latitude'][index]
    nyc311.loc[index,'Longitude'] = Filter_1['Longitude'][index]


```
Solve the remaining address.
```{python}
# Solve the remaining address

Filter_1 = nyc311[nyc311['Latitude'].isnull()]

Filter_1 = Filter_1[Filter_1['Incident Address'].notnull()]

Address = Filter_1['Incident Address'] + ' NY '

for index in Address.index:
    geocode = RateLimiter(GoogleV3(api_key='AIzaSyDhsJ5roz0w0ll0YegLJZn-niSBjm1ns5A').geocode, min_delay_seconds=1)
    location = geocode(Address[index], timeout = 10)
    if location is not None:
        Filter_1.loc[index,['Latitude',"Longitude"]] = [location.latitude,location.longitude]

for index in Filter_1.index:
    nyc311.loc[index,'Latitude']   = Filter_1['Latitude'][index]
    nyc311.loc[index,'Longitude'] = Filter_1['Longitude'][index]

```
These are the remaining latitude and longitude that is missing
```{python}
# Show the remaining data that has missing Latitude and Longitude

Filter_1 = nyc311[nyc311['Latitude'].isnull()]

Filter_1
```

Most of the latitude are due to most location is at hightway.

Now work on getting zipcode from available `latitude` and `longitude`.

```{python}
from uszipcode import SearchEngine

# Create a SearchEngine object
search = SearchEngine()

Filter_1 = nyc311[nyc311['Incident Zip'].isnull()]

Filter_1 = Filter_1[Filter_1['Latitude'].notnull()]

for index in Filter_1.index:
    z = search.by_coordinates(Filter_1['Latitude'][index],Filter_1['Longitude'][index], radius = 25)
    Filter_1.loc[index,'Incident Zip'] = z[0].zipcode

# Make an update
for index in Filter_1.index:
    nyc311.loc[index,'Incident Zip']   = Filter_1['Incident Zip'][index]

```

The remaining missing date still shown here, this means that the rest of the `Incident Zip` is filled!

```{python}
Filter_1 = nyc311[nyc311['Incident Zip'].isnull()]

Filter_1
```

Update `Borough` from `Incident Zip`.

```{python}
# Function that classified the borough
def nyczip2burough(zip):
    nzip = int(zip)
    if nzip >= 10001 and nzip <= 10282:
        return "MANHATTAN"
    elif nzip >= 10301 and nzip <= 10314:
        return "STATEN ISLAND"
    elif nzip >= 10451 and nzip <= 10475:
        return "BRONX"
    elif nzip >= 11004 and nzip <= 11109:
        return "QUEENS"
    elif nzip >= 11351 and nzip <= 11697:
        return "QUEENS"
    elif nzip >= 11201 and nzip <= 11256:
        return "BROOKLYN"
    else:
        return np.nan

Filter_1 = nyc311[nyc311['Borough'] == 'Unspecified']

Filter_1 = Filter_1[Filter_1['Incident Zip'].notnull()]

for index in Filter_1.index:
    burough = nyczip2burough(Filter_1.loc[index,['Incident Zip']])
    Filter_1.loc[index,'Borough'] = burough

#Update the data
for index in Filter_1.index:
  nyc311.loc[index,'Borough']   = Filter_1['Borough'][index]
```

Get `X Coordinate (State Plane)`and `Y Coordinate (State Plane)` using `stateplane`.

```{python}
import stateplane

Filter_1 = nyc311[nyc311['X Coordinate (State Plane)'].isnull()]

Filter_1 = Filter_1[Filter_1['Latitude'].notnull()]

for index in Filter_1.index:
    x, y = stateplane.from_lonlat(Filter_1['Longitude'][index],Filter_1['Latitude'][index])
    Filter_1.loc[index,'X Coordinate (State Plane)'] = x
    Filter_1.loc[index,'Y Coordinate (State Plane)'] = y

for index in Filter_1.index:
    nyc311.loc[index,'X Coordinate (State Plane)'] = Filter_1['X Coordinate (State Plane)'][index]
    nyc311.loc[index,'Y Coordinate (State Plane)'] = Filter_1['Y Coordinate (State Plane)'][index]

#Show the filled state plane 
Filter_1
```
Summary after cleaning the data.
    * There are more missing `X Coordinate (State Plane)` than `Y Coordinate (State Plane)`.
    * There is duplicate when stating `Cross Street 1`, `Cross Street 2`, `Intersection Street 1`,and  `Intersection Street 2`.
    * Agency from `DOT` seems commonly mixed up the `Closed Date` and `Created Date`.
    * `Borough` that is `unspecified` should count as `missing`.
    * Many `Park Facility Name` is `unspecified` should count as `missing`. 

Remove the request not from NYPD

```{python}
nyc311_NYPD = nyc311[nyc311['Agency'] == 'NYPD']

A = nyc311_NYPD[nyc311_NYPD['Closed Date'].isnull()]

A
```
Only one data still in progress. We can remove that too.

```{python}
nyc311_NYPD = nyc311_NYPD[nyc311_NYPD['Closed Date'].notnull()]

nyc311_NYPD['Duration (hours)'] = nyc311_NYPD['Closed Date'] - nyc311_NYPD['Created Date']

col = nyc311_NYPD.pop("Duration (hours)")

s_hours = col.dt.total_seconds() / 3600.0

nyc311_NYPD.insert(3,s_hours.name ,s_hours)

nyc311_NYPD['Day type'] = nyc311_NYPD['Created Date'].dt.dayofweek

for index in nyc311_NYPD.index:
    if nyc311_NYPD['Day type'][index] < 5:
       nyc311_NYPD.loc[index,'Day type'] = 'Weekday'
    else:
       nyc311_NYPD.loc[index,'Day type'] = 'Weekend'
       
col = nyc311_NYPD.pop("Day type")

nyc311_NYPD.insert(4,col.name ,col)

nyc311_NYPD
```

Visualize the distribution of uncensored duration by weekdays/weekend and by borough.

```{python}
# Remove the unspecified Borough
nyc311_NYPD = nyc311_NYPD[ nyc311_NYPD['Borough'] != 'Unspecified']

# Remove the zipcode that is null due to missing latitude and longitude
nyc311_NYPD = nyc311_NYPD[nyc311_NYPD['Incident Zip'].notnull()]

from plotnine import *

(
    ggplot(nyc311_NYPD, aes(x='Borough',y = 'Duration (hours)', fill='Day type'))
    + geom_boxplot()
)

```

Test whether the distributions are the same across weekdays/weekends.

```{python}
from scipy.stats import kruskal

# Create the subset of data
weekday_dur = nyc311_NYPD.loc[nyc311_NYPD['Day type'] == 'Weekday', 'Duration (hours)']

weekend_dur = nyc311_NYPD.loc[nyc311_NYPD['Day type'] == 'Weekend', 'Duration (hours)']

stat, pval = kruskal(weekday_dur, weekend_dur)

print(pval)
```
The pvalue shows that is diffeent accross weekdays and weekends.

Test whether the distributions are the same across borough.

```{python}
# Create the subset of the data
bronx = nyc311_NYPD[nyc311_NYPD['Borough'] == 'BRONX']['Duration (hours)']

brooklyn = nyc311_NYPD[nyc311_NYPD['Borough'] == 'BROOKLYN']['Duration (hours)']

manhattan = nyc311_NYPD[nyc311_NYPD['Borough'] == 'MANHATTAN']['Duration (hours)']

queens = nyc311_NYPD[nyc311_NYPD['Borough'] == 'QUEENS']['Duration (hours)']

staten_island = nyc311_NYPD[nyc311_NYPD['Borough'] == 'STATEN ISLAND']['Duration (hours)']

stat, pval = kruskal(bronx, brooklyn, manhattan, queens, staten_island)

print(pval)

```
The pvalue shows that the distribution are different across across borough. 

Lets merge with uszipcode data.

```{python}
import os
# set the default database file location
db_file = os.path.abspath("simple_db.sqlite")

import sqlite3
import pandas as pd
# change to your own path after installing uszipcode
con = sqlite3.connect(db_file)
zipdf = pd.read_sql_query("SELECT * from simple_zipcode", con)
zipdf.info()

# Change the type to float64
zipdf['zipcode'] = zipdf['zipcode'].astype('float64')

# Change the type to float64 too
nyc311_NYPD['Incident Zip'] = nyc311_NYPD['Incident Zip'].astype('float64')

merged_df = pd.merge(nyc311_NYPD, zipdf, how = 'left', left_on = 'Incident Zip', right_on = 'zipcode')

# Drop repeating data
merged_df = merged_df.drop(['zipcode','lat','lng'],axis = 1)
```

Displaying merged data.

```{python}
merged_df

```
